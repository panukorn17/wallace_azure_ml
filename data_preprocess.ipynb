{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.ml\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.entities import (\n",
    "    AzureBlobDatastore,\n",
    "    AzureFileDatastore,\n",
    "    AzureDataLakeGen1Datastore,\n",
    "    AzureDataLakeGen2Datastore,\n",
    ")\n",
    "from azure.ai.ml.entities import Environment\n",
    "import io\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "from sys import path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "subscription_id = config[\"azure_ml_subscription_ID\"]\n",
    "resource_group = config[\"resource_group\"]\n",
    "workspace = config[\"workspace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of AML workspace\n",
    "from_loc = \"DID\"\n",
    "to_loc = \"PAD\"\n",
    "data_year = \"2017\"\n",
    "datastore_name = 'hist_info_'+from_loc+'_'+to_loc+'_'+data_year\n",
    "if from_loc == \"DID\" and data_year == \"2016\":\n",
    "    uri = config[\"uri_DID_PAD_2016\"]\n",
    "elif from_loc == \"PAD\" and data_year == \"2016\":\n",
    "    uri = config[\"uri_PAD_DID_2016\"]\n",
    "elif from_loc == \"DID\" and data_year == \"2017\":\n",
    "    uri = config[\"uri_DID_PAD_2017\"]\n",
    "else:\n",
    "    uri = config[\"uri_PAD_DID_2017\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(uri)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.dirname(os.path.abspath(__file__))\n",
    "dir_path = os.path.dirnam(os.path.join(current_path, \"/DataPreprocessing/data_clean_02.py\"))\n",
    "sys.path.insert(0, dir_path)\n",
    "from data_clean_02 import data_cleaning\n",
    "\n",
    "\n",
    "dir_path = os.path.dirname(os.path.join(current_path, \"/DataPreprocessing/data_structure_next_n_stations_03.py\"))\n",
    "sys.path.insert(0, dir_path)\n",
    "from data_structure_next_n_stations_03 import data_structure_next_n_stations\n",
    "\n",
    "dir_path = os.path.dirname(os.path.join(current_path, \"/DataPreprocessing/delay_mechanism_04.py\"))\n",
    "sys.path.insert(0, dir_path)\n",
    "from delay_mechanism_04 import delay_mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedule_detail_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    df_schedule_detail = pd.read_csv(io.StringIO(df.loc[i,'5.schedule_detail']), sep=',', dtype=str)\n",
    "    df_schedule_detail = df_schedule_detail.drop(df_schedule_detail.columns[0], axis = 1)\n",
    "    df_schedule_detail_list.append(df_schedule_detail)\n",
    "# Drop that column\n",
    "df.drop(\"5.schedule_detail\", axis = 1, inplace = True)\n",
    "# Put whatever series you want in its place\n",
    "df[\"5.schedule_detail\"] = df_schedule_detail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_information, station_dwell_time_unique, OD_pairs_unique = data_cleaning(df)\n",
    "data_next_1_station = data_structure_next_n_stations(historical_information, station_dwell_time_unique, OD_pairs_unique, 1)\n",
    "data_next_1_station = delay_mechanism(data_next_1_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_next_1_station.to_csv(\"Data/data_next_1_station_\"+from_loc+\"_\"+to_loc+\"_\"+data_year+\".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
